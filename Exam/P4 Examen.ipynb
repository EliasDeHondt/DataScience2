{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3959ab7c-c52f-4912-a177-85ee5ec5a8ec",
   "metadata": {},
   "source": [
    "# P4 Examen\n",
    "- **Name**: Elias De Hondt\n",
    "- **Class**: ISB204B\n",
    "- **Course**: Data Science 2\n",
    "- **Date**: 11/06/2024\n",
    "- **StudentID**: 0160712-80\n",
    "\n",
    "> You hand in a **completed notebook**, so the **results of the calculations are also included**. Results should **not** be rounded."
   ]
  },
  {
   "cell_type": "code",
   "id": "5d6867e0-ae45-4e93-813e-23e1bbbbaf96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T10:02:58.022493Z",
     "start_time": "2024-06-11T10:02:58.015266Z"
    }
   },
   "source": [
    "# Import statements:\n",
    "from termcolor import colored # type: ignore                                          # Colored text\n",
    "from random import Random  # type: ignore                                             # Random number generator\n",
    "import math  # type: ignore                                                           # Mathematical functions\n",
    "import pandas as pd  # type: ignore                                                   # Data manipulation\n",
    "import numpy as np  # type: ignore                                                    # Scientific computing\n",
    "import matplotlib.pyplot as plt  # type: ignore                                       # Data visualization\n",
    "from scipy.stats import binom as binomial  # type: ignore                             # Binomial distribution\n",
    "from scipy.stats import norm as normal  # type: ignore                                # Normal distribution\n",
    "from scipy.stats import poisson as poisson  # type: ignore                            # Poisson distribution\n",
    "from scipy.stats import t as student  # type: ignore                                  # Student distribution\n",
    "from scipy.stats import chi2  # type: ignore                                          # Chi-squared distribution\n",
    "from scipy.stats import ttest_1samp  # type: ignore                                   # One-sample t-test\n",
    "from scipy.stats import chisquare  # type: ignore                                     # Chi-squared test\n",
    "from scipy.special import comb  # type: ignore                                        # Combinations\n",
    "from mlxtend.frequent_patterns import apriori  # type: ignore                         # Apriori algorithm\n",
    "from mlxtend.frequent_patterns import fpgrowth  # type: ignore                        # FP-growth algorithm\n",
    "from mlxtend.frequent_patterns import association_rules  # type: ignore               # Association rules\n",
    "from mlxtend.preprocessing import TransactionEncoder  # type: ignore                  # Transaction encoder\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis  # type: ignore  # Discriminant Analysis\n",
    "from tensorflow import keras  # type: ignore                                          # Deep Learning library\n",
    "from tensorflow.keras import Model  # type: ignore                                    # Model class\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization  # type: ignore  # Layers\n",
    "from tensorflow.keras.utils import to_categorical  # type: ignore                     # One-hot encoding\n",
    "from tensorflow.keras.optimizers import Adam  # type: ignore                          # Optimizer\n",
    "from livelossplot import PlotLossesKeras  # type: ignore                              # Live plot\n",
    "from keras.src.optimizers import RMSprop  # type: ignore                              # Optimizer\n",
    "from sklearn.model_selection import train_test_split  # type: ignore                  # Train-test split\n",
    "from sklearn.metrics import roc_auc_score # type: ignore                              # ROC AUC score\n",
    "from simanneal import Annealer  # type: ignore                                        # Simulated Annealing\n",
    "from inspyred import ec  # type: ignore                                               # Evolutionary Computation\n",
    "import warnings  # type: ignore                                                       # Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")                                                     # Disable warnings\n",
    "outputColor = \"blue\"                                                                  # Color for the output"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "828890e8-f957-4fa5-ae18-c67bf5c7a1a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T10:02:58.131120Z",
     "start_time": "2024-06-11T10:02:58.088026Z"
    }
   },
   "source": [
    "# Function definitions:\n",
    "def rule_filter(row, min_len, max_len):\n",
    "    \"\"\"\n",
    "    Filters a row based on the combined length of its 'antecedents' and 'consequents'.\n",
    "\n",
    "    Parameters:\n",
    "    - row (dict): A dictionary representing a row, containing 'antecedents' and 'consequents'.\n",
    "    - min_len (int): The minimum length for the combined 'antecedents' and 'consequents'.\n",
    "    - max_len (int): The maximum length for the combined 'antecedents' and 'consequents'.\n",
    "\n",
    "    Returns:\n",
    "    - bool: True if the length of 'antecedents' + 'consequents' is within the specified range, otherwise False.\n",
    "\n",
    "    Usage:\n",
    "    filtered_row = rule_filter(row, 2, 5)\n",
    "    \"\"\"\n",
    "    length = len(row['antecedents']) + len(row['consequents'])\n",
    "    return min_len <= length <= max_len\n",
    "\n",
    "\n",
    "def get_item_list(string):\n",
    "    \"\"\"\n",
    "    Converts a string representation of a list (where items are separated by semicolons and enclosed in square brackets)\n",
    "    into an actual Python list.\n",
    "\n",
    "    Parameters:\n",
    "    - string (str): A string representing a list, e.g., '[item1;item2;item3]'.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of items extracted from the input string.\n",
    "\n",
    "    Usage:\n",
    "    items = get_item_list(\"[item1;item2;item3]\")\n",
    "    \"\"\"\n",
    "    items = string[1:-1]\n",
    "    return items.split(';')\n",
    "\n",
    "\n",
    "def no_outliers(data):\n",
    "    \"\"\"\n",
    "    Removes outliers from a dataset based on the Interquartile Range (IQR) method.\n",
    "    This function calculates the first (Q1) and third quartiles (Q3), determines the interquartile range (IQR),\n",
    "    and filters out any data points that lie beyond 1.5 times the IQR from Q1 or Q3.\n",
    "\n",
    "    Parameters:\n",
    "    - data (pd.Series): A pandas Series containing numerical data from which to remove outliers.\n",
    "\n",
    "    Returns:\n",
    "    - pd.Series: The input data with outliers removed.\n",
    "\n",
    "    Usage:\n",
    "    clean_data = no_outliers(data_series)\n",
    "    \"\"\"\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    i = Q3 - Q1\n",
    "    low = Q1 - 1.5 * i\n",
    "    high = Q3 + 1.5 * i\n",
    "    outliers = data[(data < low) | (data > high)]\n",
    "\n",
    "    print(colored(f\"Low: {low}\", \"blue\"))\n",
    "    print(colored(f\"High: {high}\", \"blue\"))\n",
    "    print(colored(f\"Len: {len(data)}\", \"blue\"))\n",
    "    print(colored(f\"Outliers: {outliers.values}\\n\", \"blue\"))\n",
    "    return data[(data >= low) & (data <= high)]\n",
    "\n",
    "\n",
    "def plot_confidence_interval(population_size, sample_mean, sample_standard_deviation, degrees_freedom, plot_factor):\n",
    "    \"\"\"\n",
    "    Plots a confidence interval for a given sample mean and standard deviation, assuming a t-distribution.\n",
    "    This function visualizes the interval on a graph with the sample mean,\n",
    "    lower and upper bounds, and the t-distribution curve.\n",
    "\n",
    "    Parameters:\n",
    "    - population_size (int): The size of the population/sample.\n",
    "    - sample_mean (float): The mean of the sample.\n",
    "    - sample_standard_deviation (float): The standard deviation of the sample.\n",
    "    - degrees_freedom (int): Degrees of freedom, typically the sample size minus one.\n",
    "    - plot_factor (float): The factor used to scale the margin of error.\n",
    "\n",
    "    Returns:\n",
    "    - None: This function plots a graph directly.\n",
    "\n",
    "    Usage:\n",
    "    plot_confidence_interval(100, 50, 10, 99, 1.96)\n",
    "    \"\"\"\n",
    "    margin_of_error = plot_factor * sample_standard_deviation / np.sqrt(population_size)\n",
    "    lower_bound = sample_mean - margin_of_error\n",
    "    upper_bound = sample_mean + margin_of_error\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    x_axis = np.linspace(sample_mean - 3 * sample_standard_deviation, sample_mean + 3 * sample_standard_deviation, 1000)\n",
    "    y_axis = student.pdf(x_axis, degrees_freedom, loc=sample_mean, scale=sample_standard_deviation / np.sqrt(population_size))\n",
    "\n",
    "    plt.plot(x_axis, y_axis, label='t-distribution')\n",
    "    plt.axvline(lower_bound, color='red', linestyle='--', label='Lower Bound')\n",
    "    plt.axvline(upper_bound, color='blue', linestyle='--', label='Upper Bound')\n",
    "    plt.axvline(sample_mean, color='green', linestyle='-', label='Sample Mean')\n",
    "\n",
    "    plt.fill_betweenx(y_axis, lower_bound, upper_bound, where=(x_axis >= lower_bound) & (x_axis <= upper_bound), color='orange', label='Confidence Interval')\n",
    "\n",
    "    plt.title('Confidence Interval Plot')\n",
    "    plt.xlabel('Sample Mean')\n",
    "    plt.ylabel('Probability Density Function')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def LDA_coefficients(x, lda):\n",
    "    \"\"\"\n",
    "    Computes the Linear Discriminant Analysis (LDA) coefficients for each class.\n",
    "    This function transforms the input data using LDA and calculates the coefficients for the discriminant functions.\n",
    "\n",
    "    Parameters:\n",
    "    - X (pd.DataFrame): Input features for LDA.\n",
    "    - lda (object): Trained LDA model.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A dataframe containing the LDA coefficients for each class.\n",
    "\n",
    "    Usage:\n",
    "    coefficients = LDA_coefficients(X, lda_model)\n",
    "    \"\"\"\n",
    "    nb_col = x.shape[1]\n",
    "    matrix = np.zeros((nb_col + 1, nb_col), dtype=int)\n",
    "    Z = pd.DataFrame(data=matrix, columns=x.columns)\n",
    "    for j in range(0, nb_col):\n",
    "        Z.iloc[j, j] = 1\n",
    "    LD = lda.transform(Z)\n",
    "    resultaat = pd.DataFrame()\n",
    "    index = ['const']\n",
    "    for j in range(0, LD.shape[0] - 1):\n",
    "        index = np.append(index, 'C' + str(j + 1))\n",
    "    for i in range(0, LD.shape[1]):\n",
    "        coef = [LD[-1][i]]\n",
    "        for j in range(0, LD.shape[0] - 1):\n",
    "            coef = np.append(coef, LD[j][i] - LD[-1][i])\n",
    "        result = pd.Series(coef)\n",
    "        result.index = index\n",
    "        column_name = 'LD' + str(i + 1)\n",
    "        resultaat[column_name] = result\n",
    "    return resultaat\n",
    "\n",
    "\n",
    "def trueFalsef(matrix, columnnb=0):\n",
    "    \"\"\"\n",
    "    Calculates and prints the True Positive (TP), True Negative (TN), False Positive (FP),\n",
    "    and False Negative (FN) rates from a confusion matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - confusion_matrix (pd.DataFrame): Confusion matrix for the classification.\n",
    "    - columnnb (int): Index of the class for which to compute the metrics (default is 0).\n",
    "\n",
    "    Returns:\n",
    "    - None: This function prints the metrics directly.\n",
    "\n",
    "    Usage:\n",
    "    trueFalsef(confusion_matrix, columnnb=0)\n",
    "    \"\"\"\n",
    "\n",
    "    TP = matrix.values[columnnb][columnnb]\n",
    "    print(colored(f'TP: {TP}', 'blue'))\n",
    "    TN = np.diag(matrix).sum() - TP\n",
    "    print(colored(f'TN: {TN}', 'blue'))\n",
    "    FP = matrix.values[:, columnnb].sum() - TP\n",
    "    print(colored(f'FP: {FP}', 'blue'))\n",
    "    FN = matrix.values[columnnb, :].sum() - TP\n",
    "    print(colored(f'FN: {FN}', 'blue'))\n",
    "    return\n",
    "\n",
    "\n",
    "def calculate_confusion_metrics(matrix, class_label):\n",
    "    \"\"\"\n",
    "    Calculates the True Positive (TP), True Negative (TN), False Positive (FP), and False Negative (FN) rates\n",
    "    for a specific class from a confusion matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - confusion_matrix (pd.DataFrame): Confusion matrix for the classification.\n",
    "    - class_label (str): The label of the class for which to compute the metrics.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing the TP, TN, FP, and FN rates for the specified class.\n",
    "\n",
    "    Usage:\n",
    "    TP, TN, FP, FN = calculate_confusion_metrics(matrix, 'class1')\n",
    "    \"\"\"\n",
    "    class_index = matrix.columns.get_loc(class_label)\n",
    "    TP = matrix.iloc[class_index, class_index]\n",
    "    FP = matrix.iloc[:, class_index].sum() - TP\n",
    "    FN = matrix.iloc[class_index, :].sum() - TP\n",
    "    total_sum = matrix.values.sum()\n",
    "    TN = total_sum - (TP + FP + FN)\n",
    "\n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "\n",
    "def accuracyf(matrix):\n",
    "    \"\"\"\n",
    "    Calculates the overall accuracy from a confusion matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - confusion_matrix (pd.DataFrame): Confusion matrix for the classification.\n",
    "\n",
    "    Returns:\n",
    "    - float: The accuracy of the classification.\n",
    "\n",
    "    Usage:\n",
    "    accuracy = accuracyf(matrix)\n",
    "    \"\"\"\n",
    "    return np.diag(matrix).sum() / matrix.sum().sum()\n",
    "\n",
    "\n",
    "def precisionf(matrix):\n",
    "    \"\"\"\n",
    "    Calculates the precision for each class from a confusion matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - confusion_matrix (pd.DataFrame): Confusion matrix for the classification.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of precision values for each class.\n",
    "\n",
    "    Usage:\n",
    "    precision = precisionf(matrix)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    n = matrix.shape[1]\n",
    "    for i in range(0, n):\n",
    "        TP = matrix.values[i][i]\n",
    "        results = results + [TP / matrix.values[:, i].sum()]\n",
    "    return results\n",
    "\n",
    "\n",
    "def recallf(matrix):\n",
    "    \"\"\"\n",
    "    Calculates the recall for each class from a confusion matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - confusion_matrix (pd.DataFrame): Confusion matrix for the classification.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of recall values for each class.\n",
    "\n",
    "    Usage:\n",
    "    recall = recallf(matrix)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    n = matrix.shape[0]\n",
    "    for i in range(0, n):\n",
    "        TP = matrix.values[i][i]\n",
    "        results = results + [TP / matrix.values[i, :].sum()]\n",
    "    return results\n",
    "\n",
    "\n",
    "def f_measuref(matrix, beta):\n",
    "    \"\"\"\n",
    "    Calculates the F-measure (F1 score) for each class from a confusion matrix using a specified beta value.\n",
    "\n",
    "    Parameters:\n",
    "    - confusion_matrix (pd.DataFrame): Confusion matrix for the classification.\n",
    "    - beta (float): The beta value to weigh precision and recall (default is 1, which gives the F1 score).\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of F-measure values for each class.\n",
    "\n",
    "    Usage:\n",
    "    f_measure = f_measuref(matrix, beta=1)\n",
    "    \"\"\"\n",
    "    precisionarray = precisionf(matrix)\n",
    "    recallarray = recallf(matrix)\n",
    "    fmeasure = []\n",
    "    n = len(precisionarray)\n",
    "    for i in range(0, n):\n",
    "        p = precisionarray[i]\n",
    "        r = recallarray[i]\n",
    "        fmeasure = fmeasure + [((beta * beta + 1) * p * r) / (beta * beta * p + r)]\n",
    "    return fmeasure\n",
    "\n",
    "\n",
    "def overview_metrieken(matrix, beta):\n",
    "    \"\"\"\n",
    "    Provides an overview of classification metrics (precision, recall, F-measure) for each class in a confusion matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - confusion_matrix (pd.DataFrame): Confusion matrix for the classification.\n",
    "    - beta (float): The beta value to weigh precision and recall for the F-measure (default is 1).\n",
    "\n",
    "    Returns:\n",
    "    - list: A list containing a dataframe with precision, recall, and F-measure for each class.\n",
    "\n",
    "    Usage:\n",
    "    metrics_overview = overview_metrieken(matrix, beta=1)\n",
    "    \"\"\"\n",
    "    overview_1 = np.transpose(precisionf(matrix))\n",
    "    overview_2 = np.transpose(recallf(matrix))\n",
    "    overview_3 = np.transpose(f_measuref(matrix, beta))\n",
    "    overview_table = pd.DataFrame(data=np.array([overview_1, overview_2, overview_3]), columns=matrix.index)\n",
    "    overview_table.index = ['precision', 'recall', 'fx']\n",
    "    return [overview_table]\n",
    "\n",
    "\n",
    "def positiveratesf(matrix):\n",
    "    \"\"\"\n",
    "    Calculates and prints the True Positive Rate (TPR) and False Positive Rate (FPR) for a\n",
    "    binary classification confusion matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - confusion_matrix (pd.DataFrame): Confusion matrix for binary classification.\n",
    "\n",
    "    Returns:\n",
    "    - None: This function prints the TPR and FPR directly.\n",
    "\n",
    "    Usage:\n",
    "    positiveratesf(matrix)\n",
    "    \"\"\"\n",
    "    if (matrix.shape[0] == 2) & (matrix.shape[1] == 2):\n",
    "        TPR = matrix.values[0][0] / matrix.values[0, :].sum()\n",
    "        print(colored(f\"TPR: {TPR}\", \"blue\"))\n",
    "        FPR = matrix.values[1][0] / matrix.values[1, :].sum()\n",
    "        print(colored(f\"FPR: {FPR}\", \"blue\"))\n",
    "    return\n",
    "\n",
    "\n",
    "def plot_rocf(y_true, y_score, title='ROC Curve', **kwargs):\n",
    "    \"\"\"\n",
    "    Plots the Receiver Operating Characteristic (ROC) curve and calculates the Area Under the Curve (AUC) for a set of\n",
    "    true labels and predicted scores. It also highlights the optimal threshold on the ROC curve.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true (array-like): True binary labels.\n",
    "    - y_score (array-like): Target scores, probability estimates of the positive class.\n",
    "    - title (str): Title of the ROC curve plot (default is 'ROC Curve').\n",
    "    - **kwargs (dict): Additional keyword arguments for customizing the plot.\n",
    "\n",
    "    Returns:\n",
    "    - None: This function plots the ROC curve directly.\n",
    "\n",
    "    Usage:\n",
    "    plot_rocf(y_true, y_score, title='My ROC Curve', pos_label=1, figsize=(8, 8))\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "    if 'pos_label' in kwargs:\n",
    "        fpr, tpr, thresholds = roc_curve(y_true=y_true, y_score=y_score, pos_label=kwargs.get('pos_label'))\n",
    "        auc = roc_auc_score(y_true, y_score)\n",
    "    else:\n",
    "        fpr, tpr, thresholds = roc_curve(y_true=y_true, y_score=y_score)\n",
    "        auc = roc_auc_score(y_true, y_score)\n",
    "\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "    figsize = kwargs.get('figsize', (7, 7))\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    ax.grid(linestyle='--')\n",
    "\n",
    "    ax.plot(fpr, tpr, color='darkorange', label='AUC: {}'.format(auc))\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('False Positive Rate (FPR)')\n",
    "    ax.set_ylabel('True Positive Rate (TPR)')\n",
    "    ax.fill_between(fpr, tpr, alpha=0.3, color='darkorange', edgecolor='black')\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "\n",
    "    ax.scatter(fpr[optimal_idx], tpr[optimal_idx], label='optimal cutoff {:.2f} on ({:.2f},{:.2f})'.format(optimal_threshold, fpr[optimal_idx], tpr[optimal_idx]), color='red')\n",
    "    ax.plot([fpr[optimal_idx], fpr[optimal_idx]], [0, tpr[optimal_idx]], linestyle='--', color='red')\n",
    "    ax.plot([0, fpr[optimal_idx]], [tpr[optimal_idx], tpr[optimal_idx]], linestyle='--', color='red')\n",
    "\n",
    "    ax.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluate_classifier(matrix, beta=1, threshold=0.9):\n",
    "    \"\"\"\n",
    "    Evaluates a classifier based on its confusion matrix and specified threshold for various metrics.\n",
    "    This function checks if the classifier meets the threshold criteria for accuracy, precision, recall, and F1-score.\n",
    "\n",
    "    Parameters:\n",
    "    - confusion_matrix (pd.DataFrame): Confusion matrix for the classification.\n",
    "    - beta (float): The beta value to weigh precision and recall for the F-measure (default is 1).\n",
    "    - threshold (float): The threshold value to evaluate the metrics (default is 0.9).\n",
    "\n",
    "    Returns:\n",
    "    - None: This function prints the evaluation result directly.\n",
    "\n",
    "    Usage:\n",
    "    evaluate_classifier(confusion_matrix, beta=1, threshold=0.9)\n",
    "    \"\"\"\n",
    "    TP = np.diag(matrix).sum()\n",
    "    TN = np.sum(np.diag(matrix)) - TP\n",
    "    accuracy = (TP + TN) / matrix.sum().sum()\n",
    "\n",
    "    n = matrix.shape[1]\n",
    "    precision = [np.diag(matrix)[i] / np.sum(matrix.iloc[i, :]) if np.sum(matrix.iloc[i, :]) > 0 else 0 for i in range(0, n)]\n",
    "\n",
    "    n = matrix.shape[0]\n",
    "    recall = [np.diag(matrix)[i] / np.sum(matrix.iloc[:, i]) if np.sum(matrix.iloc[:, i]) > 0 else 0 for i in range(0, n)]\n",
    "\n",
    "    f1_score = [((beta ** 2 + 1) * p * r) / ((beta ** 2 * p) + r) if (p + r) > 0 else 0 for p, r in zip(precision, recall)]\n",
    "\n",
    "    if accuracy >= threshold and all(prec >= threshold for prec in precision) and all(rec >= threshold for rec in recall) and all(f1 >= threshold for f1 in f1_score):\n",
    "        print(colored(f\"This is a good classifier with a threshold of {threshold * 100}%\", \"blue\"))\n",
    "    else:\n",
    "        print(colored(f\"This is a bad classifier with a threshold of {threshold * 100}%\", \"blue\"))\n",
    "\n",
    "\n",
    "def categorize_variables(df):\n",
    "    \"\"\"\n",
    "    Categorize columns in a DataFrame into potential dependent (categorical)\n",
    "    and independent (numerical) variables for Discriminant Analysis.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing the data to be analyzed.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing two lists:\n",
    "        - dependent_vars (list): List of column names suitable as dependent variables (categorical).\n",
    "        - independent_vars (list): List of column names suitable as independent variables (numerical).\n",
    "    \"\"\"\n",
    "    independentVars = []\n",
    "    dependentVars = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            independentVars.append(col)\n",
    "        elif pd.api.types.is_categorical_dtype(df[col]) or pd.api.types.is_object_dtype(\n",
    "                df[col]) or pd.api.types.is_bool_dtype(df[col]):\n",
    "            dependentVars.append(col)\n",
    "\n",
    "    return independentVars, dependentVars\n",
    "\n",
    "\n",
    "def find_best_threshold(y_true, y_score, beta=1):\n",
    "    \"\"\"\n",
    "    Finds the optimal threshold for classification by maximizing the F1-score based on the precision-recall curve.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true (array-like): True binary labels.\n",
    "    - y_score (array-like): Target scores, probability estimates of the positive class.\n",
    "    - beta (float): The beta value to weigh precision and recall for the F-measure (default is 1).\n",
    "\n",
    "    Returns:\n",
    "    - float: The optimal threshold that maximizes the F1-score.\n",
    "\n",
    "    Usage:\n",
    "    best_threshold = find_best_threshold(y_true, y_score, beta=1)\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_score)\n",
    "    f1_score = [(beta ** 2 + 1) * p * r / ((beta ** 2 * p) + r) if (p != 0 and r != 0) else 0 for p, r in\n",
    "                zip(precision, recall)]\n",
    "    optimal_idx = f1_score.index(max(f1_score))\n",
    "    return thresholds[optimal_idx]\n",
    "\n",
    "\n",
    "def obj_func(solution, weights):\n",
    "    \"\"\"\n",
    "    Objective function for the Traveling Salesman Problem (TSP) that evaluates the quality of a solution.\n",
    "    This function calculates the total distance traveled based on the given solution.\n",
    "\n",
    "    Parameters:\n",
    "    - solution (list): A list representing the order of cities to visit.\n",
    "    - weights (list): A list of weights representing the distances between cities.\n",
    "\n",
    "    Returns:\n",
    "    - float: The total distance traveled based on the solution.\n",
    "\n",
    "    Usage:\n",
    "    distance = obj_func(solution, weights)\n",
    "    \"\"\"\n",
    "    n = int(math.sqrt(len(solution)))\n",
    "    leaveOK = np.array([sum(solution[i::n]) for i in range(n)])\n",
    "    arriveOK = np.array([sum(solution[i * n:(i + 1) * n]) for i in range(n)])\n",
    "    notStayingOK = sum(solution[0::n + 1])\n",
    "    city, loop_length = 0, 0\n",
    "    while loop_length < n + 1 and (loop_length := loop_length + 1):\n",
    "        city = next((i for i in range(n) if solution[city * n + i]), 0)\n",
    "        if not solution[city * n + city]: break\n",
    "    return np.sum(solution * weights) if notStayingOK == 0 and all(arriveOK) and all(leaveOK) and loop_length == n \\\n",
    "        else 1000 * n + np.sum(solution * weights)\n",
    "\n",
    "\n",
    "def most_important_variable(independentVariables, dependentVariable):\n",
    "    \"\"\"\n",
    "    Finds the most important variable for Linear Discriminant Analysis (LDA) based on the coefficients.\n",
    "    This function fits an LDA model and returns the variable with the highest absolute coefficient.\n",
    "\n",
    "    Parameters:\n",
    "    - independent_vars (pd.DataFrame): Input features for LDA.\n",
    "    - dependent_var (pd.Series): Target variable for LDA.\n",
    "\n",
    "    Returns:\n",
    "    - pd.Series: A series containing the most important variable and its coefficient.\n",
    "\n",
    "    Usage:\n",
    "    important_var = most_important_variable(independent_vars, dependent_var)\n",
    "    \"\"\"\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    lda.fit(independentVariables, dependentVariable)\n",
    "    coef_df = pd.DataFrame({'Variable': independentVariables.columns, 'Coefficient': lda.coef_[0]})\n",
    "\n",
    "    coef_df['Absolute Coefficient'] = coef_df['Coefficient'].abs()\n",
    "\n",
    "    return coef_df.loc[coef_df['Absolute Coefficient'].idxmax()]"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "dae70c5b-63e2-491d-9b21-99c86db0e830",
   "metadata": {},
   "source": "## Questions 1"
  },
  {
   "cell_type": "code",
   "id": "ac4c918a-4b02-4bb1-9565-89d586d96b33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T10:02:58.146988Z",
     "start_time": "2024-06-11T10:02:58.133298Z"
    }
   },
   "source": "print(colored(f\"Here is the requested solution: {1}\", outputColor))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34mHere is the requested solution: 1\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "7ac7f699-4cf3-4340-a4b1-ba827b7aa5c2",
   "metadata": {},
   "source": "## Questions 2"
  },
  {
   "cell_type": "code",
   "id": "ff5da0df-8794-4ded-aebf-3e9864a9ba8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T10:02:58.162707Z",
     "start_time": "2024-06-11T10:02:58.148662Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "4d11afd7-805a-43fa-ae0a-d6586ff890ab",
   "metadata": {},
   "source": "## Questions 3"
  },
  {
   "cell_type": "code",
   "id": "b4e55c97-d34c-43f1-ad7c-1ec6e5a2a110",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-11T10:02:58.177927Z",
     "start_time": "2024-06-11T10:02:58.164919Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "64f25185-545e-4be6-b962-c91a797be1ba",
   "metadata": {},
   "source": "## Questions 4"
  },
  {
   "cell_type": "code",
   "id": "c4df4a6a-b3b7-4095-917c-5e3da6da1c01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T10:02:58.193135Z",
     "start_time": "2024-06-11T10:02:58.178953Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "89237de3-3964-4b84-b5fc-5ee88171b4bb",
   "metadata": {},
   "source": "## Questions 5"
  },
  {
   "cell_type": "code",
   "id": "c2a5ccee-d5cc-417e-89c7-826aed37bd01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T10:02:58.208121Z",
     "start_time": "2024-06-11T10:02:58.195332Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "7b140ba7-f4f4-4539-b1cb-fdb5ad7102e9",
   "metadata": {},
   "source": "## Questions 6"
  },
  {
   "cell_type": "code",
   "id": "ec4b3037-1e47-4bcf-9621-2332caef960a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T10:02:58.224099Z",
     "start_time": "2024-06-11T10:02:58.210487Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "e77505d8-0810-4912-95a4-bccf39ebe657",
   "metadata": {},
   "source": "## Questions 7"
  },
  {
   "cell_type": "code",
   "id": "8589797e-4b15-4f6a-985b-459ae554cd3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T10:02:58.239938Z",
     "start_time": "2024-06-11T10:02:58.227122Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "57a6ea6e-cd52-44ad-a1e2-811761154da6",
   "metadata": {},
   "source": "## Questions 8"
  },
  {
   "cell_type": "code",
   "id": "900853de-87a1-4527-96fd-57a5fb1ff460",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T10:02:58.255930Z",
     "start_time": "2024-06-11T10:02:58.241938Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "31779cad-0871-48fb-b23d-f48ae6dc1c23",
   "metadata": {},
   "source": "## Questions 9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T10:02:58.271170Z",
     "start_time": "2024-06-11T10:02:58.257143Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d5ad7ddc74726a68",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "1a41d866-a773-494d-ae60-2c2016740f81",
   "metadata": {},
   "source": "## Questions 10"
  },
  {
   "cell_type": "code",
   "id": "e6c0dd60-eb5e-4edd-9960-99b5c6b735d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T10:02:58.286354Z",
     "start_time": "2024-06-11T10:02:58.274846Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
